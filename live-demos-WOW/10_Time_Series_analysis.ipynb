{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b25266",
   "metadata": {},
   "source": [
    "# Time series analysis and visualisation\n",
    "\n",
    "Heavily inspired by Jennifer Walker's tutorial: https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "# Use seaborn style defaults and set the default figure size\n",
    "sns.set_theme(rc={'figure.figsize':(11, 4)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8c5ca",
   "metadata": {},
   "source": [
    "#### The Open Power Systems Dataset (OPSD)\n",
    "\n",
    "In this demo, we will be using the daily time series of Open Power System Data (OPSD) for Germany. Germany has been rapidly expanding its renewable energy production in the 2000s-2010s. The data set includes country-wide totals of electricity consumption, wind power production, and solar power production for the years 2006-2017. You can read more about the data here: https://www.kaggle.com/mvianna10/germany-electricity-power-for-20062017.\n",
    "\n",
    "We will download the CSV dataset from GitHub: https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv\n",
    "\n",
    "Electricity production and consumption are reported as daily totals in gigawatt-hours (GWh). The columns of the data file are:\n",
    "\n",
    "* **Date** — The date (yyyy-mm-dd format)\n",
    "* **Consumption** — Electricity consumption in GWh\n",
    "* **Wind** — Wind power production in GWh\n",
    "* **Solar** — Solar power production in GWh\n",
    "* **Wind+Solar** — Sum of wind and solar power production in GWh\n",
    "\n",
    "We will explore how electricity production and consumption in Germany have changed over time, using pandas time series tools to answer questions such as:\n",
    "\n",
    "* When is electricity consumption typically highest and lowest?\n",
    "* How do wind and solar power production vary with seasons of the year?\n",
    "* What are the long-term trends in electricity consumption, solar power, and wind power?\n",
    "* How do wind and solar power production compare with electricity consumption, and how has this ratio changed over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv'\n",
    ")\n",
    "opsd_daily.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c063fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a370bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc5690",
   "metadata": {},
   "source": [
    "### Time series data structures\n",
    "\n",
    "Before we dive into the OPSD data, let’s briefly introduce the main pandas data structures for working with dates and times. In pandas, a single point in time is represented as a Timestamp. We can use the to_datetime() function to create Timestamps from strings in a wide variety of date/time formats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c67835",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85823b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily[\"Date\"] = pd.to_datetime(opsd_daily[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef6c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02caf1",
   "metadata": {},
   "source": [
    "Now that the `Date` column is of the `datetime64` type, we can set it as the DataFrame’s index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611be2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily = opsd_daily.set_index('Date')\n",
    "opsd_daily.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89837dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b05217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an alternative, we could set the \"Date\" columns as datetime64\n",
    "# and set it as an index\n",
    "opsd_daily = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv',\n",
    "    index_col=0,\n",
    "    parse_dates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee745a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612940e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns with year, month, and weekday name\n",
    "opsd_daily['Year'] = opsd_daily.index.year\n",
    "opsd_daily['Month'] = opsd_daily.index.month\n",
    "opsd_daily['Weekday Name'] = opsd_daily.index.day_name()\n",
    "# Display a random sampling of 5 rows\n",
    "opsd_daily.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b2b0aa",
   "metadata": {},
   "source": [
    "### Time-based indexing\n",
    "\n",
    "This works the same as regular indexing and slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760788e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.loc['2017-07-07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6d4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.loc['2012-01-01':'2013-07-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07045563",
   "metadata": {},
   "source": [
    "## Partial string indexing\n",
    "\n",
    "Another very handy feature of pandas time series is partial-string indexing, where we can select all date/times which partially match a given string.\n",
    "\n",
    "You could use it to get entire months or years of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0710423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the whole of July 2015\n",
    "opsd_daily.loc['2015-07']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6505efe3",
   "metadata": {},
   "source": [
    "### Time series data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f14826",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily['Consumption'].plot(linewidth=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f61164d",
   "metadata": {},
   "source": [
    "The `plot()` method has chosen pretty good tick locations (every two years) and labels (the years) for the x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_plot = ['Consumption', 'Solar', 'Wind']\n",
    "axes = opsd_daily[cols_plot].plot(\n",
    "    marker='.',\n",
    "    alpha=0.5,\n",
    "    linestyle='None',\n",
    "    figsize=(11, 9),\n",
    "    subplots=True\n",
    ")\n",
    "for ax in axes:\n",
    "    ax.set_ylabel('Daily Totals (GWh)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89326d07",
   "metadata": {},
   "source": [
    "What kind of interesting patterns do you see visualising the data?\n",
    "\n",
    "### Seasonality\n",
    "\n",
    "All three time series clearly exhibit periodicity—often referred to as *seasonality* in time series analysis—in which a pattern repeats again and again at regular time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7327424",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = opsd_daily.loc['2017', 'Consumption'].plot()\n",
    "ax.set_ylabel('Daily Consumption (GWh)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41610269",
   "metadata": {},
   "source": [
    "We can see that there are weekly oscillations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = opsd_daily.loc['2017-06':'2017-07', 'Consumption'].plot(\n",
    "    marker='o',\n",
    "    linestyle='-'\n",
    ")\n",
    "ax.set_ylabel('Daily Consumption (GWh)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06138b00",
   "metadata": {},
   "source": [
    "To better visualize the weekly seasonality in electricity consumption in the plot above, it would be nice to have vertical gridlines on a weekly time scale (instead of on the first day of each month). We can customize our plot with matplotlib.dates, so let’s import that module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f083c95",
   "metadata": {},
   "source": [
    "Because date/time ticks are handled a bit differently in matplotlib.dates compared with the DataFrame’s `plot()` method, let’s create the plot directly in matplotlib. Then we use `mdates.WeekdayLocator()` and `mdates.MONDAY` to set the x-axis ticks to the first Monday of each week. We also use `mdates.DateFormatter()` to improve the formatting of the tick labels, using the format codes we saw earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84829a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(\n",
    "    opsd_daily.loc['2017-06':'2017-07', 'Consumption'],\n",
    "    marker='o',\n",
    "    linestyle='-'\n",
    ")\n",
    "ax.set_ylabel('Daily Consumption (GWh)')\n",
    "ax.set_title('June-July 2017 Electricity Consumption')\n",
    "# Set x-axis major ticks to weekly interval, on Mondays\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MONDAY))\n",
    "# Format x-tick labels as 3-letter month name and day number\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbff5e9",
   "metadata": {},
   "source": [
    "Now we have vertical gridlines and nicely formatted tick labels on each Monday, so we can easily tell which days are weekdays and weekends.\n",
    "\n",
    "### Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d03e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(11, 10), sharex=True)\n",
    "for name, ax in zip(['Consumption', 'Solar', 'Wind'], axes):\n",
    "    sns.boxplot(data=opsd_daily, x='Month', y=name, ax=ax)\n",
    "ax.set_ylabel('GWh')\n",
    "ax.set_title(name)\n",
    "# Remove the automatic x-axis label from all but the bottom subplot\n",
    "if ax != axes[-1]:\n",
    "    ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=opsd_daily, x='Weekday Name', y='Consumption');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a9ebe",
   "metadata": {},
   "source": [
    "### Frequencies and frequency analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144ca4d",
   "metadata": {},
   "source": [
    "When the data points of a time series are uniformly spaced in time (e.g., hourly, daily, monthly, etc.), the time series can be associated with a frequency in pandas. For example, let’s use the `date_range()` function to create a sequence of uniformly spaced dates from `2017-03-10` through `2017-03-15` at daily frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_range(start, end, freq). For frequency strings see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases\n",
    "# for a list of frequency aliases. \"D\" = daily\n",
    "pd.date_range('2017-03-10', '2017-03-15', freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9251cb7",
   "metadata": {},
   "source": [
    "The resulting `DatetimeIndex` object has an attribute `freq` with a value of 'D', indicating daily frequency. Available frequencies in pandas include hourly ('H'), calendar daily ('D'), business daily ('B'), weekly ('W'), monthly ('M'), quarterly ('Q'), annual ('A'), and many others. Frequencies can also be specified as multiples of any of the base frequencies, for example '5D' for every five days.\n",
    "\n",
    "As another example, let’s create a date range at hourly frequency, specifying the start date and number of periods, instead of the start date and end date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range('2004-09-20', periods=8, freq='H')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d50665",
   "metadata": {},
   "source": [
    "Let’s take another look at the DatetimeIndex of our `opsd_daily` time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945dd4af",
   "metadata": {},
   "source": [
    "At the moment it has `freq` set to `None`. We did not explicitly set a freq when we loaded it from the CSV file.\n",
    "\n",
    "If we know that our data should be at a specific frequency, we can use the DataFrame’s `asfreq()` method to assign a frequency. If any date/times are missing in the data, new rows will be added for those date/times, which are either empty (`NaN`), or filled according to a specified data filling method such as forward filling or interpolation.\n",
    "\n",
    "To see how this works, let’s create a new DataFrame which contains only the Consumption data for Feb 3, 6, and 8, 2013.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select an arbitrary sequence of date/time values from a pandas time series,\n",
    "# we need to use a DatetimeIndex, rather than simply a list of date/time strings\n",
    "times_sample = pd.to_datetime(['2013-02-03', '2013-02-06', '2013-02-08'])\n",
    "# Select the specified dates and just the Consumption column\n",
    "consum_sample = opsd_daily.loc[times_sample, ['Consumption']].copy()\n",
    "consum_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542764be",
   "metadata": {},
   "source": [
    "Now we use the `asfreq()` method to convert the DataFrame to daily frequency, with a column for unfilled data, and a column for forward filled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb412f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to daily frequency, without filling any missings\n",
    "consum_freq = consum_sample.asfreq('D')\n",
    "# Create a column with missings forward filled\n",
    "consum_freq['Consumption - Forward Fill'] = consum_sample.asfreq('D', method='ffill')\n",
    "consum_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51b0cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dd7e4b4",
   "metadata": {},
   "source": [
    "In the `Consumption` column, we have the original data, with a value of NaN for any date that was missing in our consum_sample DataFrame. \n",
    "\n",
    "In the `Consumption - Forward Fill` column, the missings have been forward filled, meaning that the last value repeats through the missing rows until the next non-missing value occurs.\n",
    "\n",
    "If you’re doing any time series analysis which requires uniformly spaced data without any missings, you’ll want to use `asfreq()` to convert your time series to the specified frequency and fill any missings with an appropriate method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b24b657",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "\n",
    "It can be useful to resample a time series data to a higher or lower frequency. Resampling to a higher frequency (**upsampling**) is not very common and often involves interpolation or other data filling method — for example, interpolating hourly weather data to 10 minute intervals for input to a scientific model. Resampling to a lower frequency (**downsampling**) can usually involve some aggregation operation — for example, computing monthly sales totals from daily data. The daily OPSD data we’re working with in this tutorial was downsampled from the original hourly time series. \n",
    "\n",
    "We will focus here on downsampling, exploring how it can help us analyze our OPSD data on various time scales. We use the DataFrame’s `resample()` method, which splits the `DatetimeIndex` into time bins and groups the data by time bin. The `resample()` method returns a `Resampler` object, which is somewhat similar to a pandas `GroupBy` object. We can then apply aggregation methods such as `mean()`, `median()`, `sum()`, etc., to the data group for each time bin.\n",
    "\n",
    "Let’s try and resample the data to a weekly mean time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20037c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the data columns we want to include (i.e. exclude Year, Month, Weekday Name)\n",
    "DATA_COLUMNS = ['Consumption', 'Wind', 'Solar', 'Wind+Solar']\n",
    "# Resample to weekly frequency, aggregating with mean\n",
    "opsd_weekly_mean = opsd_daily[DATA_COLUMNS].resample('W').mean()\n",
    "opsd_weekly_mean.tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c105cc4",
   "metadata": {},
   "source": [
    "The first row above, labelled 2017-12-10, contains the mean of all the data contained in the time bin 2017-12-10 through 2017-12-16. The second row, labelled 2017-12-17, contains the mean data for the 2006-01-08 through 2017-12-23 time bin, and so on. By default, each row of the downsampled time series is labelled with the right edge of the time bin.\n",
    "\n",
    "By construction, our weekly time series has ~1/7 as many data points as the daily time series. We can confirm this by comparing the number of rows of the two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c250794",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opsd_daily.shape)\n",
    "print(opsd_weekly_mean.shape)\n",
    "print(opsd_daily.shape[0]/opsd_weekly_mean.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e3c475",
   "metadata": {},
   "source": [
    "Let’s plot the daily and weekly Wind time series together over a single six-month period to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start and end of the date range to extract\n",
    "start, end = '2017-01', '2017-06'\n",
    "# Plot daily and weekly resampled time series together\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(opsd_daily.loc[start:end, 'Wind'],\n",
    "marker='.', linestyle='-', linewidth=0.5, label='Daily')\n",
    "ax.plot(opsd_weekly_mean.loc[start:end, 'Wind'],\n",
    "marker='o', markersize=8, linestyle='-', label='Weekly Mean Resample')\n",
    "ax.set_ylabel('Wind Production (GWh)')\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24158a45",
   "metadata": {},
   "source": [
    "Now let’s resample the data to monthly frequency, aggregating with sum totals instead of the mean. \n",
    "\n",
    "Unlike aggregating with `mean()`, which sets the output to `NaN` for any period with all missing data, the default behavior of `sum()` will return output of 0 as the sum of missing data. We use the `min_count` parameter to change this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24909614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the monthly sums, setting the value to NaN for any month which has\n",
    "# fewer than 28 days of data\n",
    "opsd_monthly = opsd_daily[DATA_COLUMNS].resample('M').sum(min_count=28)\n",
    "opsd_monthly.tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78398e",
   "metadata": {},
   "source": [
    "You might notice that the monthly resampled data is labelled with the end of each month (the right bin edge), whereas the weekly resampled data is labelled with the left bin edge. By default, resampled data is labelled with the right bin edge for monthly, quarterly, and annual frequencies, and with the left bin edge for all other frequencies. This behavior and various other options can be adjusted using the parameters listed in the `resample()` documentation.\n",
    "\n",
    "Now let’s explore the monthly time series by plotting the electricity consumption as a line plot, and the wind and solar power production together as a stacked area plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(opsd_monthly['Consumption'], color='black', label='Consumption')\n",
    "opsd_monthly[['Wind', 'Solar']].plot.area(ax=ax, linewidth=0)\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.legend()\n",
    "_ = ax.set_ylabel('Monthly Total (GWh)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fee381f",
   "metadata": {},
   "source": [
    "At this monthly time scale, we can clearly see the yearly seasonality in each time series, and it is also evident that electricity consumption has been fairly stable over time, while wind power production has been growing steadily, with wind + solar power comprising an increasing share of the electricity consumed.\n",
    "\n",
    "Let’s explore this further by resampling to annual frequency and computing the ratio of `Wind+Solar` to `Consumption` for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d82c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the annual sums, setting the value to NaN for any year which has\n",
    "# fewer than 360 days of data\n",
    "opsd_annual = opsd_daily[DATA_COLUMNS].resample('A').sum(min_count=360)\n",
    "# The default index of the resampled DataFrame is the last day of each year,\n",
    "# ('2006-12-31', '2007-12-31', etc.) so to make life easier, set the index\n",
    "# to the year component\n",
    "opsd_annual = opsd_annual.set_index(opsd_annual.index.year)\n",
    "opsd_annual.index.name = 'Year'\n",
    "# Compute the ratio of Wind+Solar to Consumption\n",
    "opsd_annual['Wind+Solar %'] = 100.0 * opsd_annual['Wind+Solar'] / opsd_annual['Consumption']\n",
    "opsd_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot from 2012 onwards, because there is no solar production data in earlier years\n",
    "ax = opsd_annual.loc[2012:, 'Wind+Solar %'].plot.bar(color='C0')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_title('Wind + Solar Share of Annual Electricity Consumption')\n",
    "_ = plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5719a90",
   "metadata": {},
   "source": [
    "## Rolling windows\n",
    "\n",
    "Rolling window operations are another important transformation for time series data. Similar to downsampling, rolling windows split the data into time windows and and the data in each window is aggregated with a function such as `mean()`, `median()`, `sum()`, etc. However, unlike downsampling, where the time bins do not overlap and the output is at a lower frequency than the input, rolling windows overlap and “roll” along at the same frequency as the data, so the transformed time series is at the same frequency as the original time series.\n",
    "\n",
    "By default, all data points within a window are equally weighted in the aggregation, but this can be changed by specifying window types such as Gaussian, triangular, and others. We’ll stick with the standard equally weighted window here.\n",
    "\n",
    "Let’s use the `rolling()` method to compute the 5-day rolling mean of our daily data. We use the `center=True` argument to label each window at its midpoint, so the rolling windows are:\n",
    "\n",
    "* `2006-01-01` to `2006-01-05` — labelled as `2006-01-03`\n",
    "* `2006-01-02` to `2006-01-06` — labelled as `2006-01-04`\n",
    "and so on…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_5d = opsd_daily[DATA_COLUMNS].rolling(5, center=True).mean()\n",
    "opsd_5d.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f822d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_5d.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e6a960",
   "metadata": {},
   "source": [
    "We can see that the first non-missing rolling mean value is on `2006-01-03`, because this is the midpoint of the first rolling window.\n",
    "\n",
    "To visualize the differences between rolling mean and resampling, let’s update our earlier plot of January-June 2017 solar power production to include the 7-day rolling mean along with the weekly mean resampled time series and the original daily data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affdda45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute 5-day mean\n",
    "opsd_5d_mean = opsd_daily[DATA_COLUMNS].resample('5D').mean()\n",
    "# Start and end of the date range to extract\n",
    "start, end = '2017-01', '2017-06'\n",
    "# Plot daily and weekly resampled time series together\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(opsd_daily.loc[start:end, 'Wind+Solar'],\n",
    "marker='.', linestyle='-', linewidth=0.5, label='Daily')\n",
    "ax.plot(opsd_5d_mean.loc[start:end, 'Wind+Solar'],\n",
    "marker='o', markersize=8, linestyle='-', label='5-day Mean Resample')\n",
    "ax.plot(opsd_5d.loc[start:end, 'Wind+Solar'],\n",
    "marker='.', linestyle='-', label='5-d Rolling Mean')\n",
    "ax.set_ylabel('Solar + Wind Production (GWh)')\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09314b84",
   "metadata": {},
   "source": [
    "We can see that data points in the rolling mean time series have the same spacing as the daily data, but the curve is smoother because higher frequency variability has been averaged out. In the rolling mean time series, the peaks and troughs tend to align closely with the peaks and troughs of the daily time series. In contrast, the peaks and troughs in the weekly resampled time series are less closely aligned with the daily time series, since the resampled time series is at a coarser granularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5740c",
   "metadata": {},
   "source": [
    "## Trends\n",
    "\n",
    "Time series data often exhibit some slow, gradual variability in addition to higher frequency variability such as seasonality and noise. An easy way to visualize these trends is with rolling means at different time scales.\n",
    "\n",
    "A rolling mean tends to smooth a time series by averaging out variations at frequencies much higher than the window size and averaging out any seasonality on a time scale equal to the window size. This allows lower-frequency variations in the data to be explored. Since our electricity consumption time series has weekly and yearly seasonality, let’s look at rolling means on those two time scales.\n",
    "\n",
    "We’ve already computed 7-day rolling means, so now let’s compute the yearly (365-day) rolling mean of our OPSD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3bef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The min_periods=360 argument accounts for a few isolated missing days in the\n",
    "# wind and solar production time series\n",
    "opsd_365d = opsd_daily[DATA_COLUMNS].rolling(\n",
    "    window=365,\n",
    "    center=True,\n",
    "    min_periods=360\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa221207",
   "metadata": {},
   "source": [
    "Let’s plot the 7-day and 365-day rolling mean electricity consumption, along with the daily time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily, 7-day rolling mean, and 365-day rolling mean time series\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(opsd_daily['Consumption'], marker='.', markersize=2, color='0.6',\n",
    "linestyle='None', label='Daily')\n",
    "ax.plot(opsd_5d['Consumption'], linewidth=2, label='5-d Rolling Mean')\n",
    "ax.plot(opsd_365d['Consumption'], color='0.2', linewidth=3,\n",
    "label='Trend (365-d Rolling Mean)')\n",
    "# Set x-ticks to yearly interval and add legend and labels\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.legend()\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Consumption (GWh)')\n",
    "ax.set_title('Trends in Electricity Consumption');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c56ac",
   "metadata": {},
   "source": [
    "We can see that the 7-day rolling mean has smoothed out all the weekly seasonality, while preserving the yearly seasonality. The 7-day rolling mean reveals that while electricity consumption is typically higher in winter and lower in summer, there is a dramatic decrease for a few weeks every winter at the end of December and beginning of January, during the holidays.\n",
    "\n",
    "Looking at the yearly rolling mean time series, we can see that the long-term trend in electricity consumption is pretty flat, with a couple of periods of anomalously low consumption around 2009 and 2012-2013.\n",
    "\n",
    "Now let’s look at trends in wind and solar production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 365-day rolling mean time series of wind and solar power\n",
    "fig, ax = plt.subplots()\n",
    "for nm in ['Wind', 'Solar', 'Wind+Solar']:\n",
    "    ax.plot(opsd_365d[nm], label=nm)\n",
    "    # Set x-ticks to yearly interval, adjust y-axis limits, add legend and labels\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.set_ylim(0, 400)\n",
    "    ax.legend()\n",
    "    ax.set_ylabel('Production (GWh)')\n",
    "    ax.set_title('Trends in Electricity Production (365-d Rolling Means)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31226bf3",
   "metadata": {},
   "source": [
    "We can see a small increasing trend in solar power production and a more noticeable increasing trend in wind power production, as Germany continues to expand its capacity in those sectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b845d1e",
   "metadata": {},
   "source": [
    "## Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94afa0ef",
   "metadata": {},
   "source": [
    "We’ve learned how to wrangle, analyze, and visualize our time series data in pandas using techniques such as time-based indexing, resampling, and rolling windows. Applying these techniques to our OPSD data set, we’ve gained insights on seasonality, trends, and other interesting features of electricity consumption and production in Germany."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
